{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "#from keras_tuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n",
    "import tensorflow as tf\n",
    "from kerastuner import HyperParameter, HyperParameters\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Normalize the pixel values to the range of [0, 1].\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Add the channel dimension to the images.\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    hp_conv_layers = hp.Int(\"conv_layers\", 1, 3, default=3)\n",
    "    #hp_dropout= hp.Boolean(\"dropout\")\n",
    "    hp_dropout_rate=hp.Choice(\"dropout_rate\", values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]) \n",
    "    hp_activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'SGD', 'rmsprop'])\n",
    "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
    "    optimizer.learning_rate = hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001], default=0.01)\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x=inputs\n",
    "   \n",
    "    for i in range(hp_conv_layers):\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=hp.Int(\"filters_\" + str(i), 4, 32, step=4, default=8),\n",
    "            kernel_size=hp.Int(\"kernel_size_\" + str(i), 3, 5),\n",
    "            activation=hp_activation,\n",
    "            padding=\"same\",\n",
    "        )(x)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)    \n",
    "    x = tf.keras.layers.Dropout(hp_dropout_rate)(x)\n",
    "    \n",
    "    # The last layer contains 10 units,\n",
    "    # which is the same as the number of classes.\n",
    "    outputs = tf.keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `HyperParameters` and set the values.\n",
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 16,938\n",
      "Trainable params: 16,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(hp)\n",
    "# Test if the model runs with our data.\n",
    "#model(x_train[:100])\n",
    "# Print a summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=15,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\".\",\n",
    "    project_name=\"keras_trial\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 18s]\n",
      "val_accuracy: 0.8840000033378601\n",
      "\n",
      "Best val_accuracy So Far: 0.8923500180244446\n",
      "Total elapsed time: 00h 05m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 3, 'dropout_rate': 0.3, 'activation': 'tanh', 'optimizer': 'rmsprop', 'learning_rate': 0.001, 'filters_0': 28, 'kernel_size_0': 4, 'filters_1': 4, 'kernel_size_1': 5, 'filters_2': 16, 'kernel_size_2': 4}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 28)        476       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 4)         2804      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 35,690\n",
      "Trainable params: 35,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\keras_trial\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.3\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 28\n",
      "kernel_size_0: 4\n",
      "filters_1: 4\n",
      "kernel_size_1: 5\n",
      "filters_2: 16\n",
      "kernel_size_2: 4\n",
      "Score: 0.8923500180244446\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 20\n",
      "kernel_size_0: 3\n",
      "filters_1: 16\n",
      "kernel_size_1: 4\n",
      "filters_2: 4\n",
      "kernel_size_2: 5\n",
      "Score: 0.8853999972343445\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.2\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 4\n",
      "kernel_size_1: 4\n",
      "filters_2: 20\n",
      "kernel_size_2: 3\n",
      "Score: 0.8840000033378601\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 4\n",
      "kernel_size_0: 3\n",
      "filters_1: 20\n",
      "kernel_size_1: 3\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "Score: 0.8833999931812286\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.3\n",
      "activation: relu\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 24\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 5\n",
      "filters_2: 4\n",
      "kernel_size_2: 4\n",
      "Score: 0.8833000063896179\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 12\n",
      "kernel_size_0: 3\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 32\n",
      "kernel_size_2: 3\n",
      "Score: 0.8828500211238861\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "Score: 0.8728000223636627\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 4\n",
      "kernel_size_2: 3\n",
      "Score: 0.8721500039100647\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 12\n",
      "kernel_size_0: 4\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 20\n",
      "kernel_size_2: 3\n",
      "Score: 0.863400012254715\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.2\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.01\n",
      "filters_0: 20\n",
      "kernel_size_0: 4\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 8\n",
      "kernel_size_2: 4\n",
      "Score: 0.8513999879360199\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=2,\n",
    "    factor=3,\n",
    "    hyperband_iterations=15,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory=\".r\",\n",
    "    project_name=\"keras_trial\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 15s]\n",
      "val_accuracy: 0.10000000149011612\n",
      "\n",
      "Best val_accuracy So Far: 0.8999000191688538\n",
      "Total elapsed time: 00h 05m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .r\\keras_trial\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 24\n",
      "kernel_size_0: 4\n",
      "filters_1: 32\n",
      "kernel_size_1: 5\n",
      "filters_2: 28\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8999000191688538\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 28\n",
      "kernel_size_0: 4\n",
      "filters_1: 12\n",
      "kernel_size_1: 4\n",
      "filters_2: 28\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8903999924659729\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 12\n",
      "kernel_size_0: 4\n",
      "filters_1: 12\n",
      "kernel_size_1: 4\n",
      "filters_2: 12\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8888000249862671\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 12\n",
      "kernel_size_0: 3\n",
      "filters_1: 12\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 5\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8851000070571899\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 32\n",
      "kernel_size_0: 5\n",
      "filters_1: 8\n",
      "kernel_size_1: 3\n",
      "filters_2: 32\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8845000267028809\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.5\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 32\n",
      "kernel_size_2: 3\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8844000101089478\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 12\n",
      "kernel_size_0: 4\n",
      "filters_1: 12\n",
      "kernel_size_1: 3\n",
      "filters_2: 20\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8838000297546387\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 8\n",
      "kernel_size_0: 3\n",
      "filters_1: 8\n",
      "kernel_size_1: 4\n",
      "filters_2: 16\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8827999830245972\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.5\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 3\n",
      "filters_1: 12\n",
      "kernel_size_1: 3\n",
      "filters_2: 4\n",
      "kernel_size_2: 3\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8813999891281128\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 28\n",
      "kernel_size_0: 4\n",
      "filters_1: 4\n",
      "kernel_size_1: 4\n",
      "filters_2: 4\n",
      "kernel_size_2: 5\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.869700014591217\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 2, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.001, 'filters_0': 24, 'kernel_size_0': 4, 'filters_1': 32, 'kernel_size_1': 5, 'filters_2': 28, 'kernel_size_2': 4, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 24)        408       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        19232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 82,370\n",
      "Trainable params: 82,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = hyperband_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model_hp = hyperband_tuner.get_best_models()[0]\n",
    "best_model_hp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_tuner=BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=15,\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=0,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    "    directory=\".\",\n",
    "    project_name=\"keras_trial\",\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.8804000020027161\n",
      "\n",
      "Best val_accuracy So Far: 0.8898000121116638\n",
      "Total elapsed time: 00h 03m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bo_tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 1, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.001, 'filters_0': 32, 'kernel_size_0': 3, 'filters_1': 32, 'kernel_size_1': 5, 'filters_2': 32, 'kernel_size_2': 5}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_hps = bo_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model_hp = bo_tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\keras_trial\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.3\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 28\n",
      "kernel_size_0: 4\n",
      "filters_1: 4\n",
      "kernel_size_1: 5\n",
      "filters_2: 16\n",
      "kernel_size_2: 4\n",
      "Score: 0.8923500180244446\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 20\n",
      "kernel_size_0: 3\n",
      "filters_1: 16\n",
      "kernel_size_1: 4\n",
      "filters_2: 4\n",
      "kernel_size_2: 5\n",
      "Score: 0.8853999972343445\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.2\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 4\n",
      "kernel_size_1: 4\n",
      "filters_2: 20\n",
      "kernel_size_2: 3\n",
      "Score: 0.8840000033378601\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 4\n",
      "kernel_size_0: 3\n",
      "filters_1: 20\n",
      "kernel_size_1: 3\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "Score: 0.8833999931812286\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.3\n",
      "activation: relu\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 24\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 5\n",
      "filters_2: 4\n",
      "kernel_size_2: 4\n",
      "Score: 0.8833000063896179\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 12\n",
      "kernel_size_0: 3\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 32\n",
      "kernel_size_2: 3\n",
      "Score: 0.8828500211238861\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "Score: 0.8728000223636627\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.1\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 4\n",
      "kernel_size_2: 3\n",
      "Score: 0.8721500039100647\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 12\n",
      "kernel_size_0: 4\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 20\n",
      "kernel_size_2: 3\n",
      "Score: 0.863400012254715\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.2\n",
      "activation: tanh\n",
      "optimizer: SGD\n",
      "learning_rate: 0.01\n",
      "filters_0: 20\n",
      "kernel_size_0: 4\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 8\n",
      "kernel_size_2: 4\n",
      "Score: 0.8513999879360199\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 1, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.001, 'filters_0': 32, 'kernel_size_0': 3, 'filters_1': 32, 'kernel_size_1': 5, 'filters_2': 32, 'kernel_size_2': 5}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_hps = bo_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = hyperband_tuner.get_best_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 11\n",
      "conv_layers (Int)\n",
      "{'default': 3, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "dropout_rate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'SGD', 'rmsprop'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.1, 0.01, 0.001], 'ordered': True}\n",
      "filters_0 (Int)\n",
      "{'default': 8, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': None}\n",
      "kernel_size_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "filters_1 (Int)\n",
      "{'default': 8, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': None}\n",
      "kernel_size_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "filters_2 (Int)\n",
      "{'default': 8, 'conditions': [], 'min_value': 4, 'max_value': 32, 'step': 4, 'sampling': None}\n",
      "kernel_size_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 5, 'step': 1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4089 - accuracy: 0.8563 - val_loss: 0.3044 - val_accuracy: 0.8917\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2711 - accuracy: 0.9029 - val_loss: 0.2777 - val_accuracy: 0.9017\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2252 - accuracy: 0.9194 - val_loss: 0.2667 - val_accuracy: 0.9051\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1949 - accuracy: 0.9300 - val_loss: 0.2394 - val_accuracy: 0.9168\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1705 - accuracy: 0.9382 - val_loss: 0.2454 - val_accuracy: 0.9158\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1485 - accuracy: 0.9459 - val_loss: 0.2589 - val_accuracy: 0.9098\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1296 - accuracy: 0.9533 - val_loss: 0.2662 - val_accuracy: 0.9137\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9587 - val_loss: 0.2628 - val_accuracy: 0.9171\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9636 - val_loss: 0.2819 - val_accuracy: 0.9094\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9664 - val_loss: 0.2904 - val_accuracy: 0.9131\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9716 - val_loss: 0.3365 - val_accuracy: 0.9137\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9738 - val_loss: 0.3360 - val_accuracy: 0.9142\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0661 - accuracy: 0.9756 - val_loss: 0.3671 - val_accuracy: 0.9135\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0601 - accuracy: 0.9780 - val_loss: 0.3855 - val_accuracy: 0.9080\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0541 - accuracy: 0.9804 - val_loss: 0.4395 - val_accuracy: 0.9038\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0487 - accuracy: 0.9821 - val_loss: 0.4020 - val_accuracy: 0.9082\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0449 - accuracy: 0.9833 - val_loss: 0.4305 - val_accuracy: 0.9118\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.4918 - val_accuracy: 0.9117\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.4844 - val_accuracy: 0.9080\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.4900 - val_accuracy: 0.9103\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0336 - accuracy: 0.9872 - val_loss: 0.5343 - val_accuracy: 0.9098\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9880 - val_loss: 0.5618 - val_accuracy: 0.9047\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0305 - accuracy: 0.9886 - val_loss: 0.5527 - val_accuracy: 0.9118\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.5757 - val_accuracy: 0.9094\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0269 - accuracy: 0.9899 - val_loss: 0.5899 - val_accuracy: 0.9062\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0300 - accuracy: 0.9886 - val_loss: 0.5899 - val_accuracy: 0.9081\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.6415 - val_accuracy: 0.9087\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.6476 - val_accuracy: 0.9097\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.7043 - val_accuracy: 0.9067\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 0.7029 - val_accuracy: 0.9046\n",
      "Best epoch: 8\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "best_hps = hyperband_tuner.get_best_hyperparameters()[0]\n",
    "model = hyperband_tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of conv layes is 2\n",
      "The optimal number of filters  in the first densely-connected layer is 24 and \n",
      "The optimal number of filters  in the second densely-connected layer is 32 \n",
      "The optimal kernelsize  in the first densely-connected layer is 4 and \n",
      "The optimal kernelsize  in the second densely-connected layer is 5 \n",
      "The best dropout rate is 0.0 \n",
      "The optimal learning rate for the optimizer is 0.001. \n",
      "The optimal activation is relu\n",
      "The best optimizer is adam       \n",
      "Number of epochs with best val Accurcay of 0.9170833230018616 is 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of conv layes is {best_hps.get('conv_layers')}\n",
    "The optimal number of filters  in the first densely-connected layer is {best_hps.get('filters_0')} and \n",
    "The optimal number of filters  in the second densely-connected layer is {best_hps.get('filters_1')} \n",
    "The optimal kernelsize  in the first densely-connected layer is {best_hps.get('kernel_size_0')} and \n",
    "The optimal kernelsize  in the second densely-connected layer is {best_hps.get('kernel_size_1')} \n",
    "The best dropout rate is {best_hps.get('dropout_rate')} \n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}. \n",
    "The optimal activation is {best_hps.get('activation')}\n",
    "The best optimizer is {best_hps.get('optimizer')}       \n",
    "Number of epochs with best val Accurcay of {max(val_acc_per_epoch)} is {best_epoch}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
