{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "#from keras_tuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n",
    "import tensorflow as tf\n",
    "from kerastuner import HyperParameter, HyperParameters\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Normalize the pixel values to the range of [0, 1].\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Add the channel dimension to the images.\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    hp_conv_layers = hp.Int(\"conv_layers\", 1, 3, default=3)\n",
    "    #hp_dropout= hp.Boolean(\"dropout\")\n",
    "    hp_dropout_rate=hp.Choice(\"dropout_rate\", values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]) \n",
    "    hp_activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'SGD', 'rmsprop'])\n",
    "    hp_learningrate=hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x=inputs\n",
    "   \n",
    "    for i in range(hp_conv_layers):\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=hp.Int(\"filters_\" + str(i), 4, 32, step=4, default=8),\n",
    "            kernel_size=hp.Int(\"kernel_size_\" + str(i), 3, 5),\n",
    "            activation=hp_activation,\n",
    "            padding=\"same\",\n",
    "        )(x)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # A hyperparamter for whether to use dropout layer.\n",
    "    #if hp.Boolean(\"dropout\"):\n",
    "        #print(hp_dropout)\n",
    "    x = tf.keras.layers.Dropout(hp_dropout_rate)(x)\n",
    "    \n",
    "    # The last layer contains 10 units,\n",
    "    # which is the same as the number of classes.\n",
    "    outputs = tf.keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    '''if hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"]) == \"adam\":\n",
    "        hp_optimizer=tf.keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]), beta_1=0.9, \n",
    "                                              beta_2=0.999, epsilon=1e-07)\n",
    "    elif hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"]) == \"sgd\":\n",
    "        hp_optimizer=tf.keras.optimizers.SGD(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]),momentum=0.0)\n",
    "    elif hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"]) == \"rmsprop\":\n",
    "        hp_optimizer=tf.keras.optimizers.RMSprop(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4]),rho=0.9)\n",
    "    '''\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=hp_optimizer,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `HyperParameters` and set the values.\n",
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 16,938\n",
      "Trainable params: 16,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(hp)\n",
    "# Test if the model runs with our data.\n",
    "#model(x_train[:100])\n",
    "# Print a summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=15,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\".\",\n",
    "    project_name=\"keras_trial\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 16s]\n",
      "val_accuracy: 0.9461999833583832\n",
      "\n",
      "Best val_accuracy So Far: 0.9877499938011169\n",
      "Total elapsed time: 00h 05m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 3, 'dropout_rate': 0.1, 'activation': 'relu', 'optimizer': 'rmsprop', 'learning_rate': 0.01, 'filters_0': 20, 'kernel_size_0': 5, 'filters_1': 8, 'kernel_size_1': 5, 'filters_2': 12, 'kernel_size_2': 5}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         4008      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 12)        2412      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                23530     \n",
      "=================================================================\n",
      "Total params: 30,470\n",
      "Trainable params: 30,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\keras_trial\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.1\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "filters_0: 20\n",
      "kernel_size_0: 5\n",
      "filters_1: 8\n",
      "kernel_size_1: 5\n",
      "filters_2: 12\n",
      "kernel_size_2: 5\n",
      "Score: 0.9877499938011169\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.0001\n",
      "filters_0: 8\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 4\n",
      "filters_2: 20\n",
      "kernel_size_2: 4\n",
      "Score: 0.9828000068664551\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 20\n",
      "kernel_size_0: 3\n",
      "filters_1: 20\n",
      "kernel_size_1: 3\n",
      "filters_2: 28\n",
      "kernel_size_2: 4\n",
      "Score: 0.9802000224590302\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.1\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.0001\n",
      "filters_0: 12\n",
      "kernel_size_0: 3\n",
      "filters_1: 20\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "Score: 0.9794000089168549\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.3\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "filters_0: 12\n",
      "kernel_size_0: 5\n",
      "filters_1: 4\n",
      "kernel_size_1: 5\n",
      "filters_2: 4\n",
      "kernel_size_2: 4\n",
      "Score: 0.9792999923229218\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 4\n",
      "kernel_size_0: 4\n",
      "filters_1: 32\n",
      "kernel_size_1: 3\n",
      "filters_2: 28\n",
      "kernel_size_2: 3\n",
      "Score: 0.9760999977588654\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.01\n",
      "filters_0: 8\n",
      "kernel_size_0: 4\n",
      "filters_1: 16\n",
      "kernel_size_1: 4\n",
      "filters_2: 28\n",
      "kernel_size_2: 3\n",
      "Score: 0.9755499958992004\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: SGD\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 5\n",
      "filters_2: 4\n",
      "kernel_size_2: 3\n",
      "Score: 0.9729500114917755\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.3\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 24\n",
      "kernel_size_0: 4\n",
      "filters_1: 24\n",
      "kernel_size_1: 4\n",
      "filters_2: 8\n",
      "kernel_size_2: 4\n",
      "Score: 0.9729499816894531\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 16\n",
      "kernel_size_0: 5\n",
      "filters_1: 8\n",
      "kernel_size_1: 5\n",
      "filters_2: 28\n",
      "kernel_size_2: 4\n",
      "Score: 0.9728499948978424\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=2,\n",
    "    factor=3,\n",
    "    hyperband_iterations=15,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory=\".r\",\n",
    "    project_name=\"keras_trial\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.9544000029563904\n",
      "\n",
      "Best val_accuracy So Far: 0.9886000156402588\n",
      "Total elapsed time: 00h 05m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .r\\keras_trial\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.3\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 20\n",
      "kernel_size_0: 3\n",
      "filters_1: 24\n",
      "kernel_size_1: 3\n",
      "filters_2: 32\n",
      "kernel_size_2: 3\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9886000156402588\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.2\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "filters_0: 20\n",
      "kernel_size_0: 5\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9876000285148621\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.0001\n",
      "filters_0: 8\n",
      "kernel_size_0: 5\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 28\n",
      "kernel_size_2: 5\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9861999750137329\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.2\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.0001\n",
      "filters_0: 16\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 4\n",
      "filters_2: 8\n",
      "kernel_size_2: 3\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.984000027179718\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.0\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.0001\n",
      "filters_0: 28\n",
      "kernel_size_0: 4\n",
      "filters_1: 16\n",
      "kernel_size_1: 3\n",
      "filters_2: 16\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9828000068664551\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.3\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "filters_0: 8\n",
      "kernel_size_0: 3\n",
      "filters_1: 32\n",
      "kernel_size_1: 3\n",
      "filters_2: 28\n",
      "kernel_size_2: 5\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.982699990272522\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "dropout_rate: 0.4\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 32\n",
      "kernel_size_0: 5\n",
      "filters_1: 8\n",
      "kernel_size_1: 3\n",
      "filters_2: 20\n",
      "kernel_size_2: 3\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.982699990272522\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.4\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "filters_0: 8\n",
      "kernel_size_0: 3\n",
      "filters_1: 20\n",
      "kernel_size_1: 3\n",
      "filters_2: 28\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9812999963760376\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 2\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "filters_0: 12\n",
      "kernel_size_0: 4\n",
      "filters_1: 28\n",
      "kernel_size_1: 4\n",
      "filters_2: 24\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9800999760627747\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_layers: 1\n",
      "dropout_rate: 0.1\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "filters_0: 20\n",
      "kernel_size_0: 4\n",
      "filters_1: 20\n",
      "kernel_size_1: 5\n",
      "filters_2: 12\n",
      "kernel_size_2: 4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.9768000245094299\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 2, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'rmsprop', 'learning_rate': 0.001, 'filters_0': 20, 'kernel_size_0': 4, 'filters_1': 32, 'kernel_size_1': 5, 'filters_2': 20, 'kernel_size_2': 3, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        340       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        16032     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 79,102\n",
      "Trainable params: 79,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = hyperband_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model_hp = hyperband_tuner.get_best_models()[0]\n",
    "best_model_hp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_tuner=BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=15,\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=0,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    "    directory=\".\",\n",
    "    project_name=\"keras_trial\",\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 16s]\n",
      "val_accuracy: 0.9811000227928162\n",
      "\n",
      "Best val_accuracy So Far: 0.9890999794006348\n",
      "Total elapsed time: 00h 04m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bo_tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 3, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0001, 'filters_0': 32, 'kernel_size_0': 5, 'filters_1': 32, 'kernel_size_1': 3, 'filters_2': 32, 'kernel_size_2': 3}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_hps = bo_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model_hp = tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .r\\mnist\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': 3, 'dropout_rate': 0.0, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0001, 'filters_0': 32, 'kernel_size_0': 5, 'filters_1': 32, 'kernel_size_1': 3, 'filters_2': 32, 'kernel_size_2': 3}\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_hps = bo_tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = hyperband_tuner.get_best_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        340       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        16032     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 79,102\n",
      "Trainable params: 79,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1517 - accuracy: 0.9529 - val_loss: 0.0565 - val_accuracy: 0.9831\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.0524 - val_accuracy: 0.9859\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.0512 - val_accuracy: 0.9856\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0564 - val_accuracy: 0.9840\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0543 - val_accuracy: 0.9866\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0571 - val_accuracy: 0.9867\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0447 - val_accuracy: 0.9888\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0579 - val_accuracy: 0.9887\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0670 - val_accuracy: 0.9888\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0551 - val_accuracy: 0.9889\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0676 - val_accuracy: 0.9898\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0692 - val_accuracy: 0.9887\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0574 - val_accuracy: 0.9903\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0770 - val_accuracy: 0.9886\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0691 - val_accuracy: 0.9898\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0897 - val_accuracy: 0.9882\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0881 - val_accuracy: 0.9882\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0818 - val_accuracy: 0.9892\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0870 - val_accuracy: 0.9877\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0867 - val_accuracy: 0.9880\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0815 - val_accuracy: 0.9899\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0833 - val_accuracy: 0.9898\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0972 - val_accuracy: 0.9897\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0883 - val_accuracy: 0.9901\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1210 - val_accuracy: 0.9887\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1002 - val_accuracy: 0.9895\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1312 - val_accuracy: 0.9882\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1266 - val_accuracy: 0.9874\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1321 - val_accuracy: 0.9884\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1219 - val_accuracy: 0.9892\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1321 - val_accuracy: 0.9897\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1559 - val_accuracy: 0.9882\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1409 - val_accuracy: 0.9886\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1415 - val_accuracy: 0.9883\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1362 - val_accuracy: 0.9883\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.1295 - val_accuracy: 0.9893\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1434 - val_accuracy: 0.9890\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1200 - val_accuracy: 0.9899\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1213 - val_accuracy: 0.9891\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1591 - val_accuracy: 0.9881\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1802 - val_accuracy: 0.9875\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1630 - val_accuracy: 0.9881\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2059 - val_accuracy: 0.9876\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1523 - val_accuracy: 0.9889\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.1630 - val_accuracy: 0.9894\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1486 - val_accuracy: 0.9899\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1381 - val_accuracy: 0.9903\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2080 - val_accuracy: 0.9883\n",
      "Best epoch: 15\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = bo_tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of conv layes is 3\n",
      "The optimal number of filters  in the first densely-connected layer is 32 and \n",
      "The optimal number of filters  in the first densely-connected layer is 32 \n",
      "The optimal learning rate for the optimizer is 0.0001. \n",
      "The optimal activation is relu\n",
      "The best optimizer is adam \n",
      "Number of epochs with best val Accurcay of 0.9903333187103271 is 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of conv layes is {best_hps.get('conv_layers')}\n",
    "The optimal number of filters  in the first densely-connected layer is {best_hps.get('filters_0')} and \n",
    "The optimal number of filters  in the first densely-connected layer is {best_hps.get('filters_1')} \n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}. \n",
    "The optimal activation is {best_hps.get('activation')}\n",
    "The best optimizer is {best_hps.get('optimizer')} \n",
    "Number of epochs with best val Accurcay of {max(val_acc_per_epoch)} is {best_epoch}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
